#
# This is a Talligent Heat template for deploying OpenBook.
# Default user/pass for the OpenBook UI is: openbook / Tall!gent
# supports Juno, Kilo

heat_template_version: 2013-05-23

description: >
  Talligent Heat template for deploying OpenBook in a
  cluster scenario.

parameters:
  key_name:
    type: string
    description: Name of an existing key pair to use for the server
    constraints:
      - custom_constraint: nova.keypair
  image:
    type: string
    description: Image ID or image name to use for the server
    default: ubuntu-14.04
    constraints:
      - custom_constraint: glance.image
  flavor:
    type: string
    description: Flavor for the server to be created
    default: m1.small
    constraints:
      - custom_constraint: nova.flavor
  servers:
    type: comma_delimited_list
    label: Servers
    description: Comma separated list of servers in the cluster.
  port_id:
    type: string
    description: ID of an existing port to associate with this server
  
resources:
  wait_condition:
    type: OS::Heat::WaitCondition
    properties:
      handle: { get_resource: wait_handle }
      count: 1
      timeout: 1800

  wait_handle:
    type: OS::Heat::WaitConditionHandle
  
  security_group:
    type: OS::Neutron::SecurityGroup
    properties:
      name: openbook-haproxy
      description: Enable access to OpenBook and SSH access
      rules:
        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 22
          port_range_max: 22
        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 443
          port_range_max: 443
  
  haproxy_instance:
    type: OS::Nova::Server
    properties:
      key_name: { get_param: key_name }
      image: { get_param: image }
      flavor: { get_param: flavor }
      networks:
        - port: { get_param: port_id }
      metadata:
        servers: { get_param: servers }
      user_data_format: RAW
      user_data:
        str_replace:
          params:
            wc_notify: { get_attr: ['wait_handle', 'curl_cli'] }
          template: |
            #!/bin/bash -ex
            add-apt-repository -y ppa:vbernat/haproxy-1.5
            apt-get update
            aptitude install -y haproxy
            
            # Generate self-signed certificate
            openssl req -x509 -nodes -subj "/C=US/ST=Texas/L=Austin/O=Talligent/CN=talligent.net/emailAddress=support@talligent.com" -days 365 -newkey rsa:2048 -keyout openbook.key -out openbook.crt
            # openssl x509 -in openbook.crt -text -noout
            cat openbook.crt openbook.key > openbook.pem
            mv openbook.pem /etc/ssl/private/
            
            # update haproxy config
            sed -i "/^global/a\\\ttune.ssl.default-dh-param 2048" /etc/haproxy/haproxy.cfg
            sed -i "/mode\thttp/a\\\toption forwardfor\n\toption http-server-close" /etc/haproxy/haproxy.cfg
            cat << EOF >> /etc/haproxy/haproxy.cfg
            frontend www-https
                bind    *:443 ssl crt /etc/ssl/private/openbook.pem
                rspirep ^Location:\ http://(.*) Location:\ https://\1
                mode    http
                option  httpclose
                option  forwardfor
                reqadd  X-Forwarded-Proto:\ https
                default_backend appserver-backend
                
            backend appserver-backend
                balance roundrobin
                cookie  ROUTEID insert indirect nocache
            EOF
            
            # Add the Rackspace haproxy update example
            # save haproxy original configuration
            cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy_base.cfg
            
            # write an initial empty list of worker servers
            cat >>/etc/haproxy/servers.json <<EOF
            []
            EOF
            
            # write the update script
            cat >>/etc/haproxy/update.py <<EOF
            import sys
            import json
            import subprocess
            
            # load server list from metadata
            metadata = json.loads(sys.stdin.read())
            new_servers = json.loads(metadata.get('meta', {}).get('servers', '[]'))
            if not new_servers:
                sys.exit(1)  # bad metadata
            
            # compare against known list of servers
            current_servers = json.loads(open('/etc/haproxy/servers.json').read())
            if current_servers == new_servers:
                sys.exit(0)  # no changes
            
            # record updated list of servers
            open('/etc/haproxy/servers.json', 'wt').write(json.dumps(new_servers))
            
            # generate a new haproxy config file
            f = open('/etc/haproxy/haproxy.cfg', 'wt')
            f.write(open('/etc/haproxy/haproxy_base.cfg').read())
            #f.write("""
            #listen app *:80
            #    mode http
            #    balance roundrobin
            #    option httpclose
            #    option forwardfor
            #""")
            for i, server in enumerate(new_servers):
                f.write('    server server-{0} {1}:8080 check cookie server-{0}\n'.format(i, server))
            f.close()
            
            # reload haproxy's configuration
            print('Reloading haproxy with servers: ' + ', '.join(new_servers))
            subprocess.call(['service', 'haproxy', 'reload'])
            EOF
            
            # add a cron job to monitor the metadata and update haproxy
            crontab -l >_crontab || true
            echo "* * * * * curl -s http://169.254.169.254/openstack/latest/meta_data.json | python /etc/haproxy/update.py | /usr/bin/logger -t haproxy_update" >>_crontab
            crontab <_crontab
            rm _crontab
            
            wc_notify --data-binary '{"status": "SUCCESS"}'

outputs:
  name:
    description: Name of the HAProxy instance.
    value: { get_attr: [haproxy_instance, name] }
  ip:
    description: The IP address of the HAProxy instance.
    value: { get_attr: [haproxy_instance, first_address] }
  port:
    description: The network port of the HAProxy instance.
    value: { get_resource: port }
